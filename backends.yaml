# aegis/backends.yaml
backends:

- profile_name: ollama_local
  type: ollama
  llm_url: http://ollama:11434
  rag_url: http://retriever:8000
  voice_proxy_url: http://voiceproxy:8001
  vision_url: http://ollama-vision:11434
  api_key: ${BACKEND_API_KEY}
  model: "hf.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF:Q4_K_M"
  temperature: 0.2
  max_tokens_to_generate: 1536
  top_p: 0.9
  top_k: 40
  repetition_penalty: 1.1

- profile_name: ollama_remote
  type: ollama
  llm_url: http://10.0.0.100:11434
  api_key: ${BACKEND_API_KEY}
  model: "llama3:8b-instruct-q4_K_M"
  temperature: 0.2
  max_tokens_to_generate: 1536
  top_p: 0.9
  top_k: 40
  repetition_penalty: 1.1

- profile_name: openai_gpt4
  type: openai
  llm_url: https://api.openai.com/v1/chat/completions
  model: gpt-4-turbo
  api_key: ${OPENAI_API_KEY}
  temperature: 0.7
  max_tokens_to_generate: 2048
  top_p: 1.0
  tts_model: tts-1
  tts_voice: alloy
  stt_model: whisper-1