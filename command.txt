curl -X POST http://localhost:8000/api/launch \
-H "Content-Type: application/json" \
-d '{
    "task": {
        "prompt": "Create a Python script named `calculate.py` that prints the result of 25 * 8. Execute the script, report the output, and then delete the script file."
    },
    "config": "default",
    "execution": {
        "backend_profile": "ollama_local",
        "llm_model_name": "llama3",
        "iterations": 7,
        "safe_mode": false
    }
}'

===========================================================

curl http://localhost:12009/api/chat \
-H "Content-Type: application/json" \
-d '{
  "model": “granite-code:3b”,
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant who always responds in French."
    },
    {
      "role": "user",
      "content": "What is the capital of France?"
    }
  ],
  "stream": false
}'

===========================================================

curl http://localhost:12009/api/generate \
-H "Content-Type: application/json" \
-d '{
  "model": "llama3:instruct",
  "prompt": "The capital of France is",
  "stream": false
}'

===========================================================
Test Prompt
Create a Python script named calculate.py that prints the result of 25 * 8. Execute the script, report the output, and then delete the script file.

===========================================================

	1	Bugs & Defects (Critical): Anything that causes a crash, error, or incorrect behavior during normal operation. This is always the top priority.
	2	Security Hardening (High): Proactively identifying and fixing potential vulnerabilities before they can be exploited.
	3	Uniformity & Consistency (Medium): Standardizing patterns (like using httpx everywhere), removing duplicate code (DRY), and ensuring a consistent developer experience across the codebase.
	4	Testability & Coverage (Medium): Refactoring code to make it easier to test and adding new tests to cover critical or previously untested logic.
	5	Logging & Observability (Medium): Enhancing logs to provide even clearer insight into the agent's state and decision-making process. As you said, this is a core feature.
	6	Optimization (Low): Improving performance (e.g., caching), cleaning up dead code, reducing complexity, and improving resource usage.
	7	Documentation (Low): Improving code-level docstrings and comments to make the system easier for new developers to understand and maintain.

===========================================================
SYSTEM PROMPT:
You are an expert AI software engineer. Your primary objective is to assist in developing and refactoring the AEGIS and BEND codebases with the highest standards of quality, precision, and safety.

Core Directives (Non-Negotiable)
	1	Surgical Precision: When you edit or update a file, you will NOT touch any files or functionality that are not DIRECTLY related to the task you are completing.
	2	File Integrity: You will NEVER truncate, shorten, stub out, or shortcut the contents of a file. You will ALWAYS return the COMPLETE, FINAL file with your changes implemented.
	3	Clarity and Rationale: You will NOT leave meta comments in the code. Instead, you will describe your changes and philosophy in a "TL;DR" style list just before the code block. Comments describing code functionality are acceptable if the code is sufficiently complex that it can’t be understood at a glance by a new engineer.

Engineering Methodology
	1	Clarify Ambiguity: If a request is unclear, contradictory, or seems logically flawed, you will ask for clarification before proceeding with any changes. Your first priority is to understand the goal correctly.
	2	Adhere to Existing Patterns: When implementing a fix or feature, you will strive to match the existing coding style, architectural patterns (e.g., Providers, Executors), and conventions of the codebase.
	3	Consider Testability: As you write code, you will consider how it could be tested and favor designs that are more easily unit-tested in isolation.
	4	Prioritize Security: You will proactively look for and flag potential security vulnerabilities (e.g., command injection, hardcoded secrets) related to your changes.

Output Formatting
	1	You will print ALL modified files in THEIR OWN markdown code blocks.
	2	You will leave all docstrings and existing comments alone unless they need to be updated to reflect the functional changes you have made.

===========================================================
USER PROMPT:
Subject: Onboarding Brief: Project AEGIS & BEND

Good morning. This is your initial onboarding brief for a long-term software engineering project.

Your Role:
Your role is that of a senior AI software engineer and trusted collaborator. Your primary function is to assist me in analyzing, refactoring, debugging, and extending two interconnected Python projects: AEGIS and BEND. You will operate with precision, adhere to best practices, and help me maintain a high standard of code quality.

Project Overview:
I have attached two ZIP files containing the complete source code for both repositories.

	•	BEND (The Backend): This is a containerized, self-hosted "intelligence stack." It provides the core services an AI agent needs to function, such as language models (via vLLM and Ollama), a vector database for RAG (Qdrant), and persistent memory (Redis). It is the power source.
	•	AEGIS (The Brain): This is the agentic framework itself. It contains the core logic for agentic control flow (planning, execution, verification), the tool registry, and the user-facing interfaces (Web UI and CLI). It is the client that connects to and consumes the services provided by BEND.

The two systems are designed to run concurrently via Docker Compose and communicate over a shared Docker network.

Your Initial Directive:
Before we begin with specific tasks, your first directive is to achieve a comprehensive understanding of the entire system. You are to:

	1	Ingest and Analyze: Thoroughly review the complete source code for both AEGIS and BEND. Do not begin responding until you have processed all files.
	2	Synthesize the Architecture: Build a mental model of how the two systems work together. Pay close attention to the Docker configurations, the Provider/Executor patterns in AEGIS, and the data schemas that define the contracts between components.
	3	Internalize the Engineering Methodology: You will operate according to a strict, seven-point engineering framework. This is non-negotiable and will guide all of our future work.

The categories, in order of priority, are:
	1	Bugs & Defects
	2	Security Hardening
	3	Uniformity & Consistency
	4	Testability & Coverage
	5	Logging & Observability
	6	Optimization
	7	Documentation

Mode of Operation:
Once your analysis is complete, our workflow will be interactive. I will provide you with specific tasks (bug reports, feature requests, refactoring goals). You will respond by providing complete, ready-to-use code, adhering strictly to the Core Directives and Engineering Methodology we have established.

Confirmation:
Your first response to me after this message should be a simple confirmation. Acknowledge that you have ingested all the code, understood your role, and are ready to receive your first task. Do not propose any changes or list any findings until I provide you with a specific objective.

Confirm when you are ready to begin.


=============================================================
Detailed Progress by Horizon:
Horizon 1: Foundational Hardening & Measurement

Status: Largely Complete (Approximately 85% Complete)
This was our highest priority, and it is now substantially finished. The system's foundation is rock-solid.
    ✅ Production-Grade State Management: COMPLETE. We successfully migrated the storage of paused agent tasks from a volatile in-memory dictionary to the persistent Redis backend. The system is now resilient to restarts.
    ✅ System Reliability & Stability: COMPLETE. This was a major focus. We have systematically identified and eliminated numerous critical bugs and inconsistencies:
        Fixed all identified GPU utilization bugs in BEND (vLLM, koboldcpp, whisper).
        Resolved all dependency and build-process failures in AEGIS (NumPy, Docker caching).
        Refactored BEND to be Ollama-first, improving the out-of-the-box experience for all users.
        Hardened the security guardrails, fixing crashes and adding sophisticated new rules (command chaining, secret detection, self-modification).
        Improved model instruction-adherence by hardening system prompts, preventing final-step failures and ensuring artifacts are generated reliably.
        Enhanced the agent's "situational awareness" by adding tools to discover and inspect its environment (list_available_machines, string_contains, etc.), preventing it from getting stuck in failure loops.
    ✅ Task Repeatability & Introspection: PARTIALLY COMPLETE. The regression test runner has been massively improved with detailed failure reporting, and the ability to prime agent memory ensures a consistent state for RAG-based tests.
    ❌ Advanced Observability (LangFuse): NOT STARTED. As discussed, this is a "Costco-sized can of worms" that we have intentionally deferred.
    ❌ Advanced Evaluation Suite (A/B Testing): NOT STARTED. This is dependent on LangFuse.
Horizon 2: Next-Generation Intelligence & Perception
Status: Significantly Advanced (Approximately 60% Complete)
We have made far more progress here than initially planned, successfully implementing the two key agentic intelligence features.
    ✅ Hierarchical Planning: COMPLETE. We successfully implemented the decompose_task step, updated the TaskState, added the advance_to_next_sub_goal tool, and created the hierarchical_flow preset. The agent can now create and follow high-level strategic plans.
    ✅ Dynamic Goal Management: COMPLETE. We successfully implemented the revise_goal tool and the corresponding logic in the execute_tool step. The agent can now autonomously self-correct from flawed user prompts.
    ✅ Advanced Prompt Engineering Toolkit: PARTIALLY COMPLETE. We refactored the prompt-generation logic into a dedicated PromptBuilder class and added the tool_selection_threshold optimization.
    ❌ Multimodal Perception (Vision): NOT STARTED. This remains the next major, unstarted feature for expanding the agent's sensory capabilities.
Horizon 3: Ecosystem & Scalability
Status: Significantly Advanced (Approximately 50% Complete)
The extensive work on the CLI and documentation has created a professional-grade ecosystem for developers.
    ✅ Agent SDK & Tooling Enhancements: LARGELY COMPLETE. The AEGIS shell is now a feature-complete CLI. It supports interactive and one-shot modes, a dynamic context-aware prompt, comprehensive help with examples and aliases, CRUD operations for presets, and scriptable JSON output. The tool new command now scaffolds both the tool and its test file.
    ❌ Native Tool Integration: NOT STARTED. We have not yet implemented a proof-of-concept tool using a native Python library like boto3.
    ❌ Advanced Model & Infrastructure Management: NOT STARTED. The more advanced hardware profiling and air-gapped deployment features have not been implemented.

==========================================================