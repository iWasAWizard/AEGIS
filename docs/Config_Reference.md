# AEGIS Configuration Reference

This document provides a detailed reference for all the core YAML configuration files used by the AEGIS framework. These files give you granular control over every aspect of the agent's behavior, from its core logic to its backend connections.

## Table of Contents

1.  [`config.yaml`](#1-configyaml) - System-wide defaults and paths.
2.  [`backends.yaml`](#2-backendsyaml) - Defines connections to AI backends.
3.  [`machines.yaml`](#3-machinesyaml) - Defines remote machines for tools.
4.  [Agent Presets (`presets/*.yaml`)](#4-agent-presets-presetsyaml) - Defines agent workflows.

---

## 1. `config.yaml`

This is the main configuration file for the AEGIS application. It defines system-wide defaults and file paths.

### `defaults`

This section specifies the default runtime parameters for any agent task. These values are used unless they are overridden by a specific agent preset or a launch-time request.

-   **`backend_profile`** `(string)`: The default backend profile to use from `backends.yaml`.
    -   *Example:* `vllm_local`
-   **`llm_model_name`** `(string)`: The default model key from `models.yaml` to use for prompt formatting.
    -   *Example:* `llama3`
-   **`iterations`** `(integer)`: The default maximum number of plan-execute steps an agent can take before the task is automatically terminated.
    -   *Example:* `15`
-   **`llm_planning_timeout`** `(integer)`: The default timeout in seconds for waiting for a response from the LLM.
    -   *Example:* `300`
-   **`max_tokens_to_generate`** `(integer)`: The default maximum number of new tokens the LLM should generate for a plan.
    -   *Example:* `2048`
-   **`tool_timeout`** `(integer)`: The default timeout in seconds for any tool execution.
    -   *Example:* `120`
-   **`safe_mode`** `(boolean)`: The default safety mode. If `true`, tools marked as unsafe cannot be run.
    -   *Example:* `true`

### `paths`

This section defines the relative paths where AEGIS will store its output.

-   **`reports`**: Directory for human-readable summaries and machine-readable provenance logs.
-   **`screenshots`**: Subdirectory within `reports` for screenshots.
-   **`artifacts`**: Directory for other files generated by tools.
-   **`logs`**: Directory for structured `.jsonl` log files.
-   **`index`**: Directory for the RAG memory index files.

### `services`

This section defines the internal URLs for connecting to services provided by a backend stack like BEND.

-   **`redis_url`** `(string)`: The connection URL for the Redis server used for long-term memory.
    -   *Example:* `redis://redis:6379/0`
-   **`guardrails_url`** `(string)`: The URL for the NeMo Guardrails server's chat completion endpoint.
    -   *Example:* `http://nemoguardrails:8000/v1/chat/completions`

### `logging`

-   **`level`** `(string)`: The minimum log level to output.
    -   *Values:* `debug`, `info`, `warning`, `error`

---

## 2. `backends.yaml`

This file defines all the AI backends that AEGIS can connect to. Each entry is a "profile" that can be selected at runtime.

### Common Fields for All Profiles

-   **`profile_name`** `(string)`: A unique, human-readable name for the profile.
    -   *Example:* `vllm_local`
-   **`type`** `(string)`: The type of provider to use. This determines which other fields are required.
    -   *Values:* `vllm`, `ollama`, `openai`

### `vllm` Provider

-   **`llm_url`** `(string)`: The full URL to the vLLM server's OpenAI-compatible chat completions endpoint.
    -   *Example:* `http://vllm:8000/v1/chat/completions`
-   **`model`** `(string)`: The model name that vLLM is serving.
    -   *Example:* `aegis-agent-model`
-   *(...and other optional LLM parameters like `temperature`, `top_p`, etc.)*

### `ollama` Provider

-   **`llm_url`** `(string)`: The base URL for the Ollama API.
    -   *Example:* `http://ollama:11434/api/chat`
-   **`model`** `(string)`: The name of the model to use from Ollama (e.g., 'llama3:instruct').
-   *(...and other optional LLM parameters)*

### `openai` Provider

-   **`model`** `(string)`: The OpenAI model name to use.
    -   *Example:* `gpt-4-turbo`
-   **`api_key`** `(string)`: Your OpenAI API key. Should use environment variable substitution.
    -   *Example:* `${OPENAI_API_KEY}`
-   *(...and other fields for TTS/STT models)*

---

## 3. `machines.yaml`

This file defines remote physical or virtual machines that the agent can target with certain tools (e.g., `run_remote_command`). Each top-level key is a unique machine name.

-   **`name`** `(string)`: The agent-facing name of the machine.
-   **`ip`** `(string)`: The IP address or hostname.
-   **`platform`** `(string)`: The operating system. *Values:* `linux`, `windows`, `mac`.
-   **`username`** `(string)`: The username for SSH/WinRM connections.
-   **`password`** `(string)`: The password. Should use environment variable substitution.
    -   *Example:* `${ROOT_PASSWORD}`
-   **`ssh_port`** `(integer, optional)`: The SSH port if not 22.

---

## 4. Agent Presets (`presets/*.yaml`)

These files define the agent's core logic as a state graph. Each file represents a different workflow or "personality."

-   **`name`** `(string)`: The human-readable name of the preset.
-   **`description`** `(string)`: A short description of what the preset does.
-   **`state_type`** `(string)`: The dotted Python path to the state model. This should always be `aegis.agents.task_state.TaskState`.
-   **`entrypoint`** `(string)`: The ID of the first node to run in the graph.
-   **`nodes`** `(list of objects)`: A list of all the steps in the graph. Each node has:
    -   `id` `(string)`: A unique name for the node.
    -   `tool` `(string)`: The name of the agent step function to run (from the `node_registry`).
-   **`edges`** `(list of arrays)`: Defines the unconditional connections between nodes.
    -   *Example:* `[ "plan", "execute" ]` means the graph always goes from `plan` to `execute`.
-   **`condition_node`** `(string)`: The ID of a node whose output will be used for conditional routing.
-   **`condition_map`** `(object)`: A mapping of the possible string outputs from the `condition_node` to the next node's ID.
    -   *Example:* `{"continue": "plan", "end": "summarize"}`
-   **`interrupt_nodes`** `(list of strings, optional)`: A list of node IDs where execution should pause *before* the node is run. Used for HITL.
-   **`runtime`** `(object, optional)`: A block of default runtime overrides specific to this preset. For example, you can add a `tool_allowlist` here to create a specialist agent.